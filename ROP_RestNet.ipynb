{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RboncGx-tmgF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "\n",
        "from torch.cuda import amp\n",
        "from google.colab import drive\n",
        "from torchsummary import summary\n",
        "from PIL import Image, ImageFile\n",
        "from torchvision import transforms\n",
        "from torchvision.io import read_image\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMM5OCVZt8OW",
        "outputId": "be289a23-d48b-44c2-8813-0eb694176480"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_file_path = '/content/drive/MyDrive/Colab Notebooks/KULIAH/PRAKTIKUM/annotations.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TfHFT03qtmgK"
      },
      "outputs": [],
      "source": [
        "class ROP_Dataset(Dataset):\n",
        "    def __init__(self, txt_file, image_dir, transform=None):\n",
        "        self.image_list = pd.read_csv(txt_file, header=None)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_list.iloc[idx, 0])\n",
        "        image = Image.open(img_path)\n",
        "        img_tag = self.image_list.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        sample = {\"image\": image, \"tag\": img_tag}\n",
        "\n",
        "        return image, img_tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MdqYftUjBMbz"
      },
      "outputs": [],
      "source": [
        "MEAN = torch.tensor((0.485, 0.456, 0.406))\n",
        "STD  = torch.tensor((0.229, 0.224, 0.225))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CsxZBoELCAuW"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=MEAN, std=STD)\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.RandomRotation(15),\n",
        "    # transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGKlOA-yBPpw",
        "outputId": "43bbae7b-79b0-47c3-f4cb-3f9618426f4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7ba2fd6b5d20>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7ba2fd6b4340>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7ba2fd6b5bd0>\n"
          ]
        }
      ],
      "source": [
        "# Create Dataset Training\n",
        "dataset_train = ROP_Dataset(txt_file='./annotations/train.txt', image_dir='./annotations/images', transform=transform)\n",
        "# Create Dataset Testing\n",
        "dataset_test = ROP_Dataset(txt_file='./annotations/test.txt', image_dir='./annotations/images', transform=transform)\n",
        "# Create Dataset Validation\n",
        "dataset_valid = ROP_Dataset(txt_file='./annotations/valid.txt', image_dir='./annotations/images', transform=transform)\n",
        "\n",
        "# DataLoader Training\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
        "# DataLoader Testing\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=True)\n",
        "# DataLoader Validation\n",
        "dataloader_valid = DataLoader(dataset_valid, batch_size=32, shuffle=True)\n",
        "\n",
        "print(dataloader_train)\n",
        "print(dataloader_test)\n",
        "print(dataloader_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zwf2Ahkrvi93",
        "outputId": "120401e7-fa95-4e7d-cf0a-c9da5003ce42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda for inference\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using {device} for inference')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ifPf4NIWF6zd"
      },
      "outputs": [],
      "source": [
        "class ResNetModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNetModel, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "        # self.resnet = models.resnet18(weights=None)\n",
        "        num_ftrs = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9-m94OXHD3C",
        "outputId": "b3663bfd-1778-41d8-89d2-7a14c97f572d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 86.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Define model, criterion, and optimizer\n",
        "num_classes = 2 # Healthy & Not Healthy\n",
        "model = ResNetModel(num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ILF2ZRJJHRsa"
      },
      "outputs": [],
      "source": [
        "def train_model(learningRate, num_epochs):\n",
        "  # Define Adam optimizer with the current learning rate\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learningRate)\n",
        "\n",
        "  # Training loop\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      running_loss = 0.0\n",
        "      all_labels = []\n",
        "      all_predictions = []\n",
        "      for inputs, labels in dataloader_train:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          all_labels.extend(labels.cpu().numpy())\n",
        "          all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "      # Calculate average training loss per epoch\n",
        "      epoch_loss = running_loss / len(dataset_train)\n",
        "      precision = precision_score(all_labels, all_predictions, average='weighted')\n",
        "      recall = recall_score(all_labels, all_predictions, average='weighted')\n",
        "      accuracy = accuracy_score(all_labels, all_predictions)\n",
        "      # print(f\"LR : {learningRate} - Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "  # Evaluation loop\n",
        "  model.eval()\n",
        "  all_labels = []\n",
        "  all_predictions = []\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in dataloader_valid:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          all_labels.extend(labels.cpu().numpy())\n",
        "          all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "  precision = precision_score(all_labels, all_predictions, average='weighted')\n",
        "  recall = recall_score(all_labels, all_predictions, average='weighted')\n",
        "  accuracy = accuracy_score(all_labels, all_predictions)\n",
        "  print(f\"Learning Rate: {learningRate}, Recall: {recall:.4f}, Precision: {precision:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Q8qxToS3HQ7D"
      },
      "outputs": [],
      "source": [
        "# Define learning rates\n",
        "learning_rates = [0.001, 0.005, 0.01, 0.02, 0.03, 0.05, 0.08, 0.1, 0.15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sORvb-mNaukH",
        "outputId": "cb2b9f0c-b0c8-4dcc-af5a-e7a3996cfaa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning Rate: 0.001, Recall: 0.9857, Precision: 0.9859, Accuracy: 0.9857\n",
            "Learning Rate: 0.005, Recall: 0.9857, Precision: 0.9859, Accuracy: 0.9857\n",
            "Learning Rate: 0.01, Recall: 0.9714, Precision: 0.9714, Accuracy: 0.9714\n",
            "Learning Rate: 0.02, Recall: 0.9857, Precision: 0.9859, Accuracy: 0.9857\n",
            "Learning Rate: 0.03, Recall: 0.9571, Precision: 0.9610, Accuracy: 0.9571\n",
            "Learning Rate: 0.05, Recall: 0.9571, Precision: 0.9610, Accuracy: 0.9571\n",
            "Learning Rate: 0.08, Recall: 0.9000, Precision: 0.9378, Accuracy: 0.9000\n",
            "Learning Rate: 0.1, Recall: 0.9857, Precision: 0.9859, Accuracy: 0.9857\n",
            "Learning Rate: 0.15, Recall: 0.9571, Precision: 0.9591, Accuracy: 0.9571\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 50\n",
        "\n",
        "for lr in learning_rates:\n",
        "  train_model(lr, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IRXt86tC2vP"
      },
      "outputs": [],
      "source": [
        "# Learning Rate: 0.001, Recall: 0.9857, Precision: 0.9859, Accuracy: 0.9857\n",
        "# Learning Rate: 0.005, Recall: 0.9857, Precision: 0.9859, Accuracy: 0.9857\n",
        "# Learning Rate: 0.01, Recall: 0.9714, Precision: 0.9714, Accuracy: 0.9714\n",
        "# Learning Rate: 0.02, Recall: 0.9857, Precision: 0.9859, Accuracy: 0.9857\n",
        "# Learning Rate: 0.03, Recall: 0.9571, Precision: 0.9610, Accuracy: 0.9571\n",
        "# Learning Rate: 0.05, Recall: 0.9571, Precision: 0.9610, Accuracy: 0.9571\n",
        "# Learning Rate: 0.08, Recall: 0.9000, Precision: 0.9378, Accuracy: 0.9000\n",
        "# Learning Rate: 0.1, Recall: 0.9857, Precision: 0.9859, Accuracy: 0.9857\n",
        "# Learning Rate: 0.15, Recall: 0.9571, Precision: 0.9591, Accuracy: 0.9571"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
