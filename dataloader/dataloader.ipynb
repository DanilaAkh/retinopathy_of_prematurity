{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x167734c90>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x166c72410>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x161c8b8d0>\n"
     ]
    }
   ],
   "source": [
    "class ROP_Dataset(Dataset):\n",
    "    def __init__(self, txt_file, image_dir, transform=None):\n",
    "        self.image_list = pd.read_csv(txt_file, header=None)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_list.iloc[idx, 0])\n",
    "        image = Image.open(img_path)\n",
    "        img_tag = self.image_list.iloc[idx, 1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample = {\"image\": image, \"tag\": img_tag}\n",
    "\n",
    "        return image, img_tag\n",
    "\n",
    "MEAN = torch.tensor([0.485, 0.456, 0.406])\n",
    "STD  = torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=MEAN, std=STD)  # Normaliztion\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Create Dataset Training\n",
    "dataset_train = ROP_Dataset(txt_file='./annotations/train.txt', image_dir='./annotations/images', transform=transform)\n",
    "# Create Dataset Testing\n",
    "dataset_test = ROP_Dataset(txt_file='./annotations/test.txt', image_dir='./annotations/images', transform=transform)\n",
    "# Create Dataset Validation\n",
    "dataset_valid = ROP_Dataset(txt_file='./annotations/valid.txt', image_dir='./annotations/images', transform=transform)\n",
    "\n",
    "# DataLoader Training\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "# DataLoader Testing\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=True)\n",
    "# DataLoader Validation\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=32, shuffle=True)\n",
    "\n",
    "print(dataloader_train)\n",
    "print(dataloader_test)\n",
    "print(dataloader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet18 model\n",
    "resnet = models.resnet18(weights=None)\n",
    "# Modify the last layer to fit MNIST's 10 classes\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 10)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(5):  # Loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader_train, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:  # Print every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
