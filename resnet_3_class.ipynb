{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "RboncGx-tmgF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "\n",
        "from torch.cuda import amp\n",
        "from google.colab import drive\n",
        "from torchsummary import summary\n",
        "from PIL import Image, ImageFile\n",
        "from torchvision import transforms\n",
        "from torchvision.io import read_image\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeiXysH7UWhM",
        "outputId": "fa199ce6-47ff-46ac-ec77-5af90e161bb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMM5OCVZt8OW",
        "outputId": "109d0a25-34a5-4117-b4dc-6a0235131339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_file_path = '/content/drive/MyDrive/2_semestr/PP/annotations.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "TfHFT03qtmgK"
      },
      "outputs": [],
      "source": [
        "class ROP_Dataset(Dataset):\n",
        "    def __init__(self, txt_file, image_dir, transform=None):\n",
        "        self.image_list = pd.read_csv(txt_file, header=None)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_list.iloc[idx, 0])\n",
        "        image = Image.open(img_path)\n",
        "        img_tag = self.image_list.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        sample = {\"image\": image, \"tag\": img_tag}\n",
        "\n",
        "        return image, img_tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "MdqYftUjBMbz"
      },
      "outputs": [],
      "source": [
        "MEAN = torch.tensor((0.485, 0.456, 0.406))\n",
        "STD  = torch.tensor((0.229, 0.224, 0.225))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "CsxZBoELCAuW"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=MEAN, std=STD)\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.RandomRotation(15),\n",
        "    # transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGKlOA-yBPpw",
        "outputId": "5bde1516-d380-4589-9d5f-3611c6b837c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7a89fdf72da0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7a89002b6590>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7a89002b53c0>\n"
          ]
        }
      ],
      "source": [
        "# Create Dataset Training\n",
        "dataset_train = ROP_Dataset(txt_file='/content/drive/MyDrive/2_semestr/PP/train_3classes.txt', image_dir='./annotations/images', transform=transform)\n",
        "# Create Dataset Testing\n",
        "dataset_test = ROP_Dataset(txt_file='/content/drive/MyDrive/2_semestr/PP/test_3classes.txt', image_dir='./annotations/images', transform=transform)\n",
        "# Create Dataset Validation\n",
        "dataset_valid = ROP_Dataset(txt_file='/content/drive/MyDrive/2_semestr/PP/valid_3classes.txt', image_dir='./annotations/images', transform=transform)\n",
        "\n",
        "# DataLoader Training\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
        "# DataLoader Testing\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=True)\n",
        "# DataLoader Validation\n",
        "dataloader_valid = DataLoader(dataset_valid, batch_size=32, shuffle=True)\n",
        "\n",
        "print(dataloader_train)\n",
        "print(dataloader_test)\n",
        "print(dataloader_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zwf2Ahkrvi93",
        "outputId": "69c4785f-8c08-49eb-8b21-2c2803d80909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu for inference\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using {device} for inference')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ifPf4NIWF6zd"
      },
      "outputs": [],
      "source": [
        "class ResNetModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNetModel, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "        # self.resnet = models.resnet18(weights=None)\n",
        "        num_ftrs = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "t9-m94OXHD3C"
      },
      "outputs": [],
      "source": [
        "# Define model, criterion, and optimizer\n",
        "num_classes = 3 # Healthy & Not Healthy\n",
        "model = ResNetModel(num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ILF2ZRJJHRsa"
      },
      "outputs": [],
      "source": [
        "def train_model(learningRate, num_epochs):\n",
        "  # Define Adam optimizer with the current learning rate\n",
        "  optimizer = optim.SGD(model.parameters(), lr=learningRate)\n",
        "\n",
        "  # Training loop\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      running_loss = 0.0\n",
        "      all_labels = []\n",
        "      all_predictions = []\n",
        "      for inputs, labels in dataloader_train:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          all_labels.extend(labels.cpu().numpy())\n",
        "          all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "      # Calculate average training loss per epoch\n",
        "      epoch_loss = running_loss / len(dataset_train)\n",
        "      precision = precision_score(all_labels, all_predictions, average='weighted')\n",
        "      recall = recall_score(all_labels, all_predictions, average='weighted')\n",
        "      accuracy = accuracy_score(all_labels, all_predictions)\n",
        "      # print(f\"LR : {learningRate} - Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "  torch.save(model.state_dict(), f'model_{learningRate}.pth')\n",
        "  # Evaluation loop\n",
        "  model.eval()\n",
        "  all_labels = []\n",
        "  all_predictions = []\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in dataloader_valid:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          all_labels.extend(labels.cpu().numpy())\n",
        "          all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "  precision = precision_score(all_labels, all_predictions, average='weighted')\n",
        "  recall = recall_score(all_labels, all_predictions, average='weighted')\n",
        "  accuracy = accuracy_score(all_labels, all_predictions)\n",
        "  print(f\"Learning Rate: {learningRate}, Recall: {recall:.4f}, Precision: {precision:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Q8qxToS3HQ7D"
      },
      "outputs": [],
      "source": [
        "# Define learning rates\n",
        "learning_rates = [0.001, 0.005, 0.010, 0.020, 0.030, 0.050, 0.08, 0.1, 0.15]\n",
        "\n",
        "# 0.005, 0.010, 0.020, 0.030, 0.050, 0.08, 0.1, 0.15\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s9mCdQN3qU4A"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "sORvb-mNaukH"
      },
      "outputs": [],
      "source": [
        "# num_epochs = 50\n",
        "\n",
        "# for lr in learning_rates:\n",
        "#   train_model(lr, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "7IRXt86tC2vP"
      },
      "outputs": [],
      "source": [
        "# Learning Rate: 0.001, Recall: 0.9000, Precision: 0.8675, Accuracy: 0.9000\n",
        "# Learning Rate: 0.005, Recall: 0.9200, Precision: 0.8838, Accuracy: 0.9200\n",
        "# Learning Rate: 0.01, Recall: 0.9800, Precision: 0.9806, Accuracy: 0.9800\n",
        "# Learning Rate: 0.02, Recall: 0.9200, Precision: 0.8838, Accuracy: 0.9200\n",
        "# Learning Rate: 0.03, Recall: 0.9400, Precision: 0.9022, Accuracy: 0.9400\n",
        "# Learning Rate: 0.05, Recall: 0.9200, Precision: 0.9044, Accuracy: 0.9200\n",
        "# Learning Rate: 0.08, Recall: 0.8400, Precision: 0.8453, Accuracy: 0.8400\n",
        "# Learning Rate: 0.1, Recall: 0.8400, Precision: 0.8417, Accuracy: 0.8400\n",
        "# Learning Rate: 0.15, Recall: 0.7600, Precision: 0.7838, Accuracy: 0.7600"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "IAzBiQxOwOsI"
      },
      "outputs": [],
      "source": [
        "def test_model(learningRage):\n",
        "  model = ResNetModel(num_classes)\n",
        "  model.load_state_dict(torch.load(f'/content/drive/MyDrive/2_semestr/PP/model_3_{learningRage}.pth', map_location=torch.device('cpu')))\n",
        "  # Evaluation loop\n",
        "  model.eval()\n",
        "  all_labels = []\n",
        "  all_predictions = []\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in dataloader_test:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          all_labels.extend(labels.cpu().numpy())\n",
        "          all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "  precision = precision_score(all_labels, all_predictions, average='weighted')\n",
        "  recall = recall_score(all_labels, all_predictions, average='weighted')\n",
        "  accuracy = accuracy_score(all_labels, all_predictions)\n",
        "  print(f\"Learning Rate: {learningRage}, Recall: {recall:.4f}, Precision: {precision:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "R6tXG2ubyI9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6daae398-3774-485c-839a-ec17e39bd94a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate: 0.001, Recall: 0.8966, Precision: 0.9027, Accuracy: 0.8966\n",
            "Learning Rate: 0.005, Recall: 0.9195, Precision: 0.9222, Accuracy: 0.9195\n",
            "Learning Rate: 0.01, Recall: 0.9080, Precision: 0.9046, Accuracy: 0.9080\n",
            "Learning Rate: 0.02, Recall: 0.8966, Precision: 0.8935, Accuracy: 0.8966\n",
            "Learning Rate: 0.03, Recall: 0.9310, Precision: 0.9293, Accuracy: 0.9310\n",
            "Learning Rate: 0.05, Recall: 0.9080, Precision: 0.9184, Accuracy: 0.9080\n",
            "Learning Rate: 0.08, Recall: 0.8851, Precision: 0.9148, Accuracy: 0.8851\n",
            "Learning Rate: 0.1, Recall: 0.8851, Precision: 0.8862, Accuracy: 0.8851\n",
            "Learning Rate: 0.15, Recall: 0.7471, Precision: 0.8302, Accuracy: 0.7471\n"
          ]
        }
      ],
      "source": [
        "for lr in learning_rates:\n",
        "  test_model(lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning Rate: 0.001, Recall: 0.8966, Precision: 0.9027, Accuracy: 0.8966\n",
        "\n",
        "Learning Rate: 0.005, Recall: 0.9195, Precision: 0.9222, Accuracy: 0.9195\n",
        "\n",
        "Learning Rate: 0.01, Recall: 0.9080, Precision: 0.9046, Accuracy: 0.9080\n",
        "\n",
        "Learning Rate: 0.02, Recall: 0.8966, Precision: 0.8935, Accuracy: 0.8966\n",
        "\n",
        "Learning Rate: 0.03, Recall: 0.9310, Precision: 0.9293, Accuracy: 0.9310\n",
        "\n",
        "Learning Rate: 0.05, Recall: 0.9080, Precision: 0.9184, Accuracy: 0.9080\n",
        "\n",
        "Learning Rate: 0.08, Recall: 0.8851, Precision: 0.9148, Accuracy: 0.8851\n",
        "\n",
        "Learning Rate: 0.1, Recall: 0.8851, Precision: 0.8862, Accuracy: 0.8851\n",
        "\n",
        "Learning Rate: 0.15, Recall: 0.7471, Precision: 0.8302, Accuracy: 0.7471"
      ],
      "metadata": {
        "id": "yQkYJJn4_U5G"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}